{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992bfca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -qU pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e374b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-text-splitters\n",
      "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.1 (from langchain-community)\n",
      "  Downloading langchain_core-1.2.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.46-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML<7.0.0,>=5.3.0 (from langchain-community)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.13.3-cp312-cp312-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-community)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith<1.0.0,>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.6.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community)\n",
      "  Downloading numpy-2.4.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl.metadata (77 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.1->langchain-community)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<26.0.0,>=23.2.0 (from langchain-core<2.0.0,>=1.0.1->langchain-community)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain-core<2.0.0,>=1.0.1->langchain-community)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.0.1->langchain-community)\n",
      "  Downloading uuid_utils-0.14.0-cp39-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading orjson-3.11.5-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.32.5->langchain-community)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.32.5->langchain-community)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.32.5->langchain-community)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.32.5->langchain-community)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community)\n",
      "  Downloading greenlet-3.3.0-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.3/2.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading aiohttp-3.13.3-cp312-cp312-win_amd64.whl (455 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading langchain_core-1.2.7-py3-none-any.whl (490 kB)\n",
      "Downloading langsmith-0.6.4-py3-none-any.whl (283 kB)\n",
      "Downloading numpy-2.4.1-cp312-cp312-win_amd64.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.3 MB 8.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.8/12.3 MB 5.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/12.3 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.1/12.3 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.2/12.3 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.5/12.3 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.8/12.3 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.4/12.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.7/12.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.0/12.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading sqlalchemy-2.0.46-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 5.2 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading greenlet-3.3.0-cp312-cp312-win_amd64.whl (301 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-win_amd64.whl (46 kB)\n",
      "Downloading orjson-3.11.5-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.0/2.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 5.4 MB/s eta 0:00:00\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading uuid_utils-0.14.0-cp39-abi3-win_amd64.whl (182 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl (87 kB)\n",
      "Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl (506 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: zstandard, uuid-utils, urllib3, typing-extensions, tenacity, PyYAML, python-dotenv, propcache, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, idna, httpx-sse, h11, greenlet, frozenlist, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, typing-inspect, SQLAlchemy, requests, pydantic-core, marshmallow, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, pydantic, httpx, dataclasses-json, aiohttp, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain-classic, langchain-community\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 26.0\n",
      "    Uninstalling packaging-26.0:\n",
      "      Successfully uninstalled packaging-26.0\n",
      "Successfully installed PyYAML-6.0.3 SQLAlchemy-2.0.46 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.12.1 attrs-25.4.0 certifi-2026.1.4 charset_normalizer-3.4.4 dataclasses-json-0.6.7 frozenlist-1.8.0 greenlet-3.3.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 idna-3.11 jsonpatch-1.33 jsonpointer-3.0.0 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-core-1.2.7 langchain-text-splitters-1.1.0 langsmith-0.6.4 marshmallow-3.26.2 multidict-6.7.0 mypy-extensions-1.1.0 numpy-2.4.1 orjson-3.11.5 packaging-25.0 propcache-0.4.1 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-settings-2.12.0 python-dotenv-1.2.1 requests-2.32.5 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-extensions-4.15.0 typing-inspect-0.9.0 typing-inspection-0.4.2 urllib3-2.6.3 uuid-utils-0.14.0 yarl-1.22.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb95a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_file_path = './income_tax.pdf'\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "\n",
    "pages = []\n",
    "for doc in loader.lazy_load():\n",
    "    pages.append(doc)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f96d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2026-01-23T16:22:47+09:00', 'moddate': '2026-01-23T16:22:47+09:00', 'source': './income_tax.pdf', 'total_pages': 137, 'page': 35, 'page_label': '36'}, page_content='ë²•ì œì²˜                                                            36                                                       êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°\\nì†Œë“ì„¸ë²•\\n1. ë¹„ì¹˜ã†ê¸°ë¡í•œ ì¥ë¶€ì— ì˜í•˜ì—¬ ì‹ ê³ í•˜ì—¬ì•¼ í•  ì†Œë“ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20 ì´ìƒì„ ëˆ„ë½í•˜ì—¬ ì‹ ê³ í•œ ê²½ìš°\\n2. ê¸°ì¥ì„¸ì•¡ê³µì œì™€ ê´€ë ¨ëœ ì¥ë¶€ ë° ì¦ëª…ì„œë¥˜ë¥¼ í•´ë‹¹ ê³¼ì„¸í‘œì¤€í™•ì •ì‹ ê³ ê¸°ê°„ ì¢…ë£Œì¼ë¶€í„° 5ë…„ê°„ ë³´ê´€í•˜ì§€ ì•„ë‹ˆí•œ ê²½\\nìš°. ë‹¤ë§Œ, ì²œì¬ì§€ë³€ ë“± ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ë¶€ë“ì´í•œ ì‚¬ìœ ì— í•´ë‹¹í•˜ëŠ” ê²½ìš°ì—ëŠ” ê·¸ëŸ¬í•˜ì§€ ì•„ë‹ˆí•˜ë‹¤.\\nâ‘¢ ê¸°ì¥ì„¸ì•¡ê³µì œì— ê´€í•˜ì—¬ í•„ìš”í•œ ì‚¬í•­ì€ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•œë‹¤.\\n[ì „ë¬¸ê°œì • 2009. 12. 31.]\\n \\nì œ56ì¡°ì˜3(ì „ìê³„ì‚°ì„œ ë°œê¸‰ ì „ì†¡ì— ëŒ€í•œ ì„¸ì•¡ê³µì œ) â‘  ì´ìˆ˜ì…ê¸ˆì•¡ ë“±ì„ ê³ ë ¤í•˜ì—¬ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ì‚¬ì—…ìê°€ ì œ\\n163ì¡°ì œ1í•­ í›„ë‹¨ì— ë”°ë¥¸ ì „ìê³„ì‚°ì„œë¥¼ 2027ë…„ 12ì›” 31ì¼ê¹Œì§€ ë°œê¸‰(ì œ163ì¡°ì œ8í•­ì— ë”°ë¼ ì „ìê³„ì‚°ì„œ ë°œê¸‰ëª…ì„¸ë¥¼\\nêµ­ì„¸ì²­ì¥ì—ê²Œ ì „ì†¡í•˜ëŠ” ê²½ìš°ë¡œ í•œì •í•œë‹¤)í•˜ëŠ” ê²½ìš°ì—ëŠ” ì „ìê³„ì‚°ì„œ ë°œê¸‰ ê±´ìˆ˜ ë“±ì„ ê³ ë ¤í•˜ì—¬ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ”\\nê¸ˆì•¡ì„ í•´ë‹¹ ê³¼ì„¸ê¸°ê°„ì˜ ì‚¬ì—…ì†Œë“ì— ëŒ€í•œ ì¢…í•©ì†Œë“ì‚°ì¶œì„¸ì•¡ì—ì„œ ê³µì œí•  ìˆ˜ ìˆë‹¤. ì´ ê²½ìš° ê³µì œí•œë„ëŠ” ì—°ê°„ 100ë§Œì›\\nìœ¼ë¡œ í•œë‹¤. <ê°œì • 2021. 12. 8., 2024. 12. 31.>\\nâ‘¡ ì œ1í•­ì— ë”°ë¥¸ ì„¸ì•¡ê³µì œë¥¼ ì ìš©ë°›ìœ¼ë ¤ëŠ” ì‚¬ì—…ìëŠ” ì œ70ì¡° ë˜ëŠ” ì œ74ì¡°ì— ë”°ë¥¸ ê³¼ì„¸í‘œì¤€í™•ì •ì‹ ê³ ë¥¼ í•  ë•Œ ì¬ì •ê²½\\nì œë¶€ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ì „ìê³„ì‚°ì„œ ë°œê¸‰ ì„¸ì•¡ê³µì œì‹ ê³ ì„œë¥¼ ë‚©ì„¸ì§€ ê´€í•  ì„¸ë¬´ì„œì¥ì—ê²Œ ì œì¶œí•˜ì—¬ì•¼ í•œë‹¤.<ê°œì • 2025.\\n10. 1.>\\n[ë³¸ì¡°ì‹ ì„¤ 2014. 12. 23.]\\n \\nì œ57ì¡°(ì™¸êµ­ë‚©ë¶€ì„¸ì•¡ê³µì œ) â‘  ê±°ì£¼ìì˜ ì¢…í•©ì†Œë“ê¸ˆì•¡ ë˜ëŠ” í‡´ì§ì†Œë“ê¸ˆì•¡ì— êµ­ì™¸ì›ì²œì†Œë“ì´ í•©ì‚°ë˜ì–´ ìˆëŠ” ê²½ìš°ë¡œì„œ\\nê·¸ êµ­ì™¸ì›ì²œì†Œë“ì— ëŒ€í•˜ì—¬ ì™¸êµ­ì—ì„œ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ì™¸êµ­ì†Œë“ì„¸ì•¡(ì´í•˜ ì´ ì¡°ì—ì„œ â€œì™¸êµ­ì†Œë“ì„¸ì•¡â€ì´ë¼ í•œë‹¤)ì„\\në‚©ë¶€í•˜ì˜€ê±°ë‚˜ ë‚©ë¶€í•  ê²ƒì´ ìˆì„ ë•Œì—ëŠ” ë‹¤ìŒ ê³„ì‚°ì‹ì— ë”°ë¼ ê³„ì‚°í•œ ê¸ˆì•¡(ì´í•˜ ì´ ì¡°ì—ì„œ â€œê³µì œí•œë„ê¸ˆì•¡â€ì´ë¼ í•œë‹¤)\\në‚´ì—ì„œ ì™¸êµ­ì†Œë“ì„¸ì•¡ì„ í•´ë‹¹ ê³¼ì„¸ê¸°ê°„ì˜ ì¢…í•©ì†Œë“ì‚°ì¶œì„¸ì•¡ ë˜ëŠ” í‡´ì§ì†Œë“ ì‚°ì¶œì„¸ì•¡ì—ì„œ ê³µì œí•  ìˆ˜ ìˆë‹¤. <ê°œì •\\n2020. 12. 29.>\\nâ‘¡ ì œ1í•­(ì™¸êµ­ì†Œë“ì„¸ì•¡ì„ ì¢…í•©ì†Œë“ì‚°ì¶œì„¸ì•¡ì—ì„œ ê³µì œí•˜ëŠ” ê²½ìš°ë§Œ í•´ë‹¹í•œë‹¤)ì„ ì ìš©í•  ë•Œ ì™¸êµ­ì •ë¶€ì— ë‚©ë¶€í•˜ì˜€ê±°ë‚˜\\në‚©ë¶€í•  ì™¸êµ­ì†Œë“ì„¸ì•¡ì´ í•´ë‹¹ ê³¼ì„¸ê¸°ê°„ì˜ ê³µì œí•œë„ê¸ˆì•¡ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš° ê·¸ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì€ í•´ë‹¹ ê³¼ì„¸ê¸°ê°„ì˜ ë‹¤ìŒ\\nê³¼ì„¸ê¸°ê°„ ê°œì‹œì¼ë¶€í„° 10ë…„ ì´ë‚´ì— ëë‚˜ëŠ” ê³¼ì„¸ê¸°ê°„(ì´í•˜ ì´ ì¡°ì—ì„œ â€œì´ì›”ê³µì œê¸°ê°„â€ì´ë¼ í•œë‹¤)ìœ¼ë¡œ ì´ì›”í•˜ì—¬ ê·¸ ì´\\nì›”ëœ ê³¼ì„¸ê¸°ê°„ì˜ ê³µì œí•œë„ê¸ˆì•¡ ë‚´ì—ì„œ ê³µì œë°›ì„ ìˆ˜ ìˆë‹¤. ë‹¤ë§Œ, ì™¸êµ­ì •ë¶€ì— ë‚©ë¶€í•˜ì˜€ê±°ë‚˜ ë‚©ë¶€í•  ì™¸êµ­ì†Œë“ì„¸ì•¡ì„\\nì´ì›”ê³µì œê¸°ê°„ ë‚´ì— ê³µì œë°›ì§€ ëª»í•œ ê²½ìš° ê·¸ ê³µì œë°›ì§€ ëª»í•œ ì™¸êµ­ì†Œë“ì„¸ì•¡ì€ ì œ33ì¡°ì œ1í•­ì œ1í˜¸ì—ë„ ë¶ˆêµ¬í•˜ê³  ì´ì›”ê³µ\\nì œê¸°ê°„ì˜ ì¢…ë£Œì¼ ë‹¤ìŒ ë‚ ì´ ì†í•˜ëŠ” ê³¼ì„¸ê¸°ê°„ì˜ ì†Œë“ê¸ˆì•¡ì„ ê³„ì‚°í•  ë•Œ í•„ìš”ê²½ë¹„ì— ì‚°ì…í•  ìˆ˜ ìˆë‹¤.<ê°œì • 2013. 1. 1.,\\n2018. 12. 31., 2020. 12. 29., 2022. 12. 31.>\\nâ‘¢ êµ­ì™¸ì›ì²œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ìê°€ ì¡°ì„¸ì¡°ì•½ì˜ ìƒëŒ€êµ­ì—ì„œ ê·¸ êµ­ì™¸ì›ì²œì†Œë“ì— ëŒ€í•˜ì—¬ ì†Œë“ì„¸ë¥¼ ê°ë©´ë°›ì€ ì„¸ì•¡ì˜ ìƒ\\në‹¹ì•¡ì€ ê·¸ ì¡°ì„¸ì¡°ì•½ì—ì„œ ì •í•˜ëŠ” ë²”ìœ„ì—ì„œ ì œ1í•­ì— ë”°ë¥¸ ì„¸ì•¡ê³µì œì˜ ëŒ€ìƒì´ ë˜ëŠ” ì™¸êµ­ì†Œë“ì„¸ì•¡ìœ¼ë¡œ ë³¸ë‹¤.<ê°œì •\\n2020. 12. 29.>\\nâ‘£ ê±°ì£¼ìì˜ ì¢…í•©ì†Œë“ê¸ˆì•¡ ë˜ëŠ” í‡´ì§ì†Œë“ê¸ˆì•¡ì— ì™¸êµ­ë²•ì¸ìœ¼ë¡œë¶€í„° ë°›ëŠ” ì´ìµì˜ ë°°ë‹¹ì´ë‚˜ ì‰ì—¬ê¸ˆì˜ ë¶„ë°°ì•¡(ì´í•˜ ì´\\ní•­ì—ì„œ â€œìˆ˜ì…ë°°ë‹¹ê¸ˆì•¡â€ì´ë¼ í•œë‹¤)ì´ í¬í•¨ë˜ì–´ ìˆëŠ” ê²½ìš°ë¡œì„œ ê·¸ ì™¸êµ­ë²•ì¸ì˜ ì†Œë“ì— ëŒ€í•˜ì—¬ í•´ë‹¹ ì™¸êµ­ë²•ì¸ì´ ì•„ë‹ˆë¼\\nì¶œììì¸ ê±°ì£¼ìê°€ ì§ì ‘ ë‚©ì„¸ì˜ë¬´ë¥¼ ë¶€ë‹´í•˜ëŠ” ë“± ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ìš”ê±´ì„ ê°–ì¶˜ ê²½ìš°ì—ëŠ” ê·¸ ì™¸êµ­ë²•ì¸ì˜ ì†Œë“\\nì— ëŒ€í•˜ì—¬ ì¶œììì¸ ê±°ì£¼ìì—ê²Œ ë¶€ê³¼ëœ ì™¸êµ­ì†Œë“ì„¸ì•¡ ì¤‘ í•´ë‹¹ ìˆ˜ì…ë°°ë‹¹ê¸ˆì•¡ì— ëŒ€ì‘í•˜ëŠ” ê²ƒìœ¼ë¡œì„œ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aba6e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting py-zerox\n",
      "  Using cached py_zerox-0.0.7-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles>=23.0 (from py-zerox)\n",
      "  Using cached aiofiles-25.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: aiohttp>=3.9.5 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from py-zerox) (3.13.3)\n",
      "Collecting pdf2image>=1.17.0 (from py-zerox)\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting litellm>=1.44.15 (from py-zerox)\n",
      "  Using cached litellm-1.81.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting aioshutil>=1.5 (from py-zerox)\n",
      "  Using cached aioshutil-1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting PyPDF2>=3.0.1 (from py-zerox)\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.5->py-zerox) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.5->py-zerox) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.5->py-zerox) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.5->py-zerox) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.5->py-zerox) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.5->py-zerox) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.5->py-zerox) (1.22.0)\n",
      "Collecting click (from litellm>=1.44.15->py-zerox)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fastuuid>=0.13.0 (from litellm>=1.44.15->py-zerox)\n",
      "  Downloading fastuuid-0.14.0-cp312-cp312-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 (from litellm>=1.44.15->py-zerox)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm>=1.44.15->py-zerox) (0.28.1)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm>=1.44.15->py-zerox)\n",
      "  Using cached importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting jinja2<4.0.0,>=3.1.2 (from litellm>=1.44.15->py-zerox)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.23.0 (from litellm>=1.44.15->py-zerox)\n",
      "  Using cached jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting openai>=2.8.0 (from litellm>=1.44.15->py-zerox)\n",
      "  Using cached openai-2.15.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm>=1.44.15->py-zerox) (2.12.5)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm>=1.44.15->py-zerox) (1.2.1)\n",
      "Collecting tiktoken>=0.7.0 (from litellm>=1.44.15->py-zerox)\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tokenizers (from litellm>=1.44.15->py-zerox)\n",
      "  Using cached tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting pillow (from pdf2image>=1.17.0->py-zerox)\n",
      "  Downloading pillow-12.1.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiosignal>=1.4.0->aiohttp>=3.9.5->py-zerox) (4.15.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.23.0->litellm>=1.44.15->py-zerox) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.23.0->litellm>=1.44.15->py-zerox) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.23.0->litellm>=1.44.15->py-zerox) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.23.0->litellm>=1.44.15->py-zerox) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.44.15->py-zerox) (0.16.0)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm>=1.44.15->py-zerox)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.2->litellm>=1.44.15->py-zerox)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.23.0->litellm>=1.44.15->py-zerox)\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.23.0->litellm>=1.44.15->py-zerox)\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.25.0 (from jsonschema<5.0.0,>=4.23.0->litellm>=1.44.15->py-zerox)\n",
      "  Downloading rpds_py-0.30.0-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=2.8.0->litellm>=1.44.15->py-zerox)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=2.8.0->litellm>=1.44.15->py-zerox)\n",
      "  Downloading jiter-0.12.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai>=2.8.0->litellm>=1.44.15->py-zerox)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai>=2.8.0->litellm>=1.44.15->py-zerox)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.44.15->py-zerox) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.44.15->py-zerox) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.44.15->py-zerox) (0.4.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.7.0->litellm>=1.44.15->py-zerox)\n",
      "  Downloading regex-2026.1.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tiktoken>=0.7.0->litellm>=1.44.15->py-zerox) (2.32.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from click->litellm>=1.44.15->py-zerox) (0.4.6)\n",
      "Collecting huggingface-hub<2.0,>=0.16.4 (from tokenizers->litellm>=1.44.15->py-zerox)\n",
      "  Using cached huggingface_hub-1.3.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox)\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox)\n",
      "  Using cached fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox) (6.0.3)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox)\n",
      "  Using cached typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.44.15->py-zerox) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.44.15->py-zerox) (2.6.3)\n",
      "Using cached py_zerox-0.0.7-py3-none-any.whl (23 kB)\n",
      "Using cached aiofiles-25.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached aioshutil-1.6-py3-none-any.whl (4.7 kB)\n",
      "Using cached litellm-1.81.1-py3-none-any.whl (11.8 MB)\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Downloading fastuuid-0.14.0-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.0/4.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.6/4.7 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.5/4.7 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 6.8 MB/s eta 0:00:00\n",
      "Using cached importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.26.0-py3-none-any.whl (90 kB)\n",
      "Using cached openai-2.15.0-py3-none-any.whl (1.1 MB)\n",
      "Downloading tiktoken-0.12.0-cp312-cp312-win_amd64.whl (878 kB)\n",
      "   ---------------------------------------- 0.0/878.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 878.7/878.7 kB 6.6 MB/s eta 0:00:00\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading pillow-12.1.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.3/7.0 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.9/7.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.2/7.0 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.8/7.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 6.8 MB/s eta 0:00:00\n",
      "Using cached tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached huggingface_hub-1.3.3-py3-none-any.whl (536 kB)\n",
      "Downloading jiter-0.12.0-cp312-cp312-win_amd64.whl (205 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2026.1.15-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Downloading rpds_py-0.30.0-cp312-cp312-win_amd64.whl (240 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: zipp, tqdm, sniffio, shellingham, rpds-py, regex, PyPDF2, pillow, MarkupSafe, jiter, hf-xet, grpcio, fsspec, filelock, fastuuid, distro, click, aioshutil, aiofiles, typer-slim, tiktoken, referencing, pdf2image, jinja2, importlib-metadata, openai, jsonschema-specifications, huggingface-hub, tokenizers, jsonschema, litellm, py-zerox\n",
      "Successfully installed MarkupSafe-3.0.3 PyPDF2-3.0.1 aiofiles-25.1.0 aioshutil-1.6 click-8.3.1 distro-1.9.0 fastuuid-0.14.0 filelock-3.20.3 fsspec-2026.1.0 grpcio-1.76.0 hf-xet-1.2.0 huggingface-hub-1.3.3 importlib-metadata-8.7.1 jinja2-3.1.6 jiter-0.12.0 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 litellm-1.81.1 openai-2.15.0 pdf2image-1.17.0 pillow-12.1.0 py-zerox-0.0.7 referencing-0.37.0 regex-2026.1.15 rpds-py-0.30.0 shellingham-1.5.4 sniffio-1.3.1 tiktoken-0.12.0 tokenizers-0.22.2 tqdm-4.67.1 typer-slim-0.21.1 zipp-3.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install py-zerox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1928a46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae063cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2cb0b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -q nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e164e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f543285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pdf2image in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pdf2image) (12.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe10c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì´ 137p ë¶„ì„ ì‹œì‘ (ëª¨ë¸: Gemini 2.0 Flash)\n",
      "ğŸ“„ [1/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:30:15 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [2/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:30:36 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [3/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:30:57 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [4/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:31:17 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [5/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:31:37 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [6/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:32:00 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [7/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:32:21 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [8/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:32:41 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [9/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:33:03 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [10/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:33:24 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [11/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:33:44 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [12/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:34:06 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [13/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:34:28 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [14/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:34:48 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [15/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:35:09 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [16/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:35:30 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [17/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:35:51 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [18/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:36:12 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [19/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:36:33 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [20/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:36:56 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [21/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:37:20 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [22/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:37:41 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [23/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:38:04 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [24/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:38:24 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [25/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:38:45 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [26/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:39:05 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [27/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:39:27 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [28/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:39:49 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [29/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:40:12 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [30/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:40:33 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [31/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:40:52 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [32/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:41:13 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [33/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:41:35 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [34/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:41:58 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [35/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:42:20 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [36/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:42:42 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [37/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:43:04 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [38/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:43:26 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [39/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:43:49 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [40/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:44:16 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [41/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:44:39 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [42/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:45:02 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [43/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:45:24 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [44/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:45:47 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [45/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:46:09 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [46/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:46:30 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [47/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:46:54 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [48/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:47:14 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [49/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:47:37 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [50/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:48:00 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [51/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:48:22 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [52/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:48:46 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [53/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:49:07 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [54/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:49:27 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [55/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:49:48 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [56/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:50:12 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [57/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:50:33 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [58/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:50:55 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [59/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:51:18 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [60/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:51:39 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [61/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:52:01 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [62/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:52:24 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [63/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:52:43 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [64/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:53:01 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [65/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:53:22 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [66/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:53:43 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [67/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:54:04 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [68/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:54:26 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [69/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:54:45 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [70/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:55:06 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [71/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:55:28 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [72/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:55:50 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [73/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:56:11 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [74/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:56:32 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [75/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:56:54 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [76/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:57:14 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [77/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:57:32 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [78/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:57:53 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [79/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:58:17 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [80/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:58:38 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [81/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:58:58 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [82/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:59:16 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [83/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:59:45 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [84/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:00:08 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [85/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:00:30 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [86/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:00:49 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [87/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:01:11 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [88/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:01:32 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [89/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:01:54 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [90/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:02:17 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [91/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:02:39 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [92/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:03:02 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [93/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:03:24 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [94/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:03:46 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [95/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:04:08 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [96/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:04:29 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [97/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:04:52 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [98/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:05:15 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [99/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:05:36 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [100/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:05:59 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [101/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:06:23 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [102/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:06:44 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [103/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:07:03 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [104/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:07:25 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [105/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:07:47 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [106/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:08:08 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [107/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:08:30 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [108/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:08:52 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [109/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:09:15 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [110/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:09:36 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [111/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:09:58 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [112/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:10:19 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [113/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:10:40 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [114/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:11:01 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [115/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:11:24 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [116/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:11:46 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [117/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:12:08 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [118/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:12:29 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [119/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:12:50 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [120/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:13:13 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [121/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:13:37 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [122/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:13:59 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âŒ ì—ëŸ¬: 'cp949' codec can't \n",
      "ğŸ“„ [122/137] ë¶„ì„ ì¤‘ (ì‹œë„ 2)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:14:16 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âŒ ì—ëŸ¬: 'cp949' codec can't \n",
      "ğŸ“„ [122/137] ë¶„ì„ ì¤‘ (ì‹œë„ 3)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:14:32 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âŒ ì—ëŸ¬: 'cp949' codec can't \n",
      "ğŸ“„ [122/137] ë¶„ì„ ì¤‘ (ì‹œë„ 4)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:14:49 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âŒ ì—ëŸ¬: 'cp949' codec can't \n",
      "ğŸ“„ [122/137] ë¶„ì„ ì¤‘ (ì‹œë„ 5)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:15:06 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âŒ ì—ëŸ¬: 'cp949' codec can't \n",
      " -> ğŸ”´ 122p ìµœì¢… ì‹¤íŒ¨\n",
      "ğŸ“„ [123/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:15:23 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [124/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:15:47 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [125/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:16:11 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [126/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:16:34 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [127/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:16:54 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [128/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:17:16 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [129/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:17:37 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [130/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:17:59 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âŒ ì—ëŸ¬: 'cp949' codec can't \n",
      "ğŸ“„ [130/137] ë¶„ì„ ì¤‘ (ì‹œë„ 2)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:18:15 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [131/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:18:39 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [132/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:19:01 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [133/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:19:24 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [134/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:19:45 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [135/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:20:07 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [136/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:20:28 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "ğŸ“„ [137/137] ë¶„ì„ ì¤‘ (ì‹œë„ 1)..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:20:49 - LiteLLM:WARNING\u001b[0m: transformation.py:329 - No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n",
      "WARNING:LiteLLM:No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> âœ…\n",
      "\n",
      "âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ! './documents' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import logging\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from pyzerox import zerox\n",
    "from pdf2image import convert_from_path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ì„¤ì • ì´ˆê¸°í™”\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "logging.getLogger(\"pyzerox\").setLevel(logging.CRITICAL)\n",
    "\n",
    "# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì • (í•œì -> í•œê¸€ ë³€í™˜ ê°•ì¡°)\n",
    "KOREAN_LAW_PROMPT = (\n",
    "    \"ë‹¹ì‹ ì€ ë²•ë¥  ì „ë¬¸ OCR ì—”ì§„ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ì— í•œìê°€ ì„ì—¬ ìˆë”ë¼ë„, \"\n",
    "    \"ëª¨ë“  í•œìë¥¼ ë…ìŒ(í•œê¸€)ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê¸°ë¡í•˜ì„¸ìš”. ì˜ˆ: 'å…§åœ‹æ³•äºº' -> 'ë‚´êµ­ë²•ì¸'. \"\n",
    "    \"í•œìë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³  ìˆœìˆ˜ í•œê¸€ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”. \"\n",
    "    \"ë²•ì¡°ë¬¸ ë²ˆí˜¸ì™€ í•­ ë²ˆí˜¸ë¥¼ ìœ ì§€í•˜ë©° ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì§€ì¼œì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "async def process_income_tax_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    total_pages = len(reader.pages)\n",
    "    \n",
    "    doc_dir = os.path.abspath(\"./documents\")\n",
    "    chunk_dir = os.path.abspath(\"./chunks\")\n",
    "    os.makedirs(doc_dir, exist_ok=True)\n",
    "    os.makedirs(chunk_dir, exist_ok=True)\n",
    "\n",
    "    # ëª¨ë¸ ì„¤ì • (Gemini 2.0 Flash)\n",
    "    target_model = \"gemini/gemini-2.0-flash\"\n",
    "\n",
    "    print(f\"ğŸš€ ì´ {total_pages}p ë¶„ì„ ì‹œì‘ (ëª¨ë¸: Gemini 2.0 Flash)\")\n",
    "\n",
    "    for i in range(total_pages):\n",
    "        page_num = i + 1\n",
    "        md_output_path = os.path.join(doc_dir, f\"page_{page_num}.md\")\n",
    "        \n",
    "        # [ì´ì–´í•˜ê¸°] ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•˜ê³  ë‚´ìš©ì´ ìˆë‹¤ë©´ ê±´ë„ˆëœ€\n",
    "        if os.path.exists(md_output_path) and os.path.getsize(md_output_path) > 100:\n",
    "            if page_num % 10 == 0:\n",
    "                print(f\"â­ï¸ {page_num}p ê±´ë„ˆëœ€...\")\n",
    "            continue\n",
    "\n",
    "        pdf_chunk_path = os.path.join(chunk_dir, f\"page_{page_num}.pdf\")\n",
    "        writer = PdfWriter()\n",
    "        writer.add_page(reader.pages[i])\n",
    "        with open(pdf_chunk_path, \"wb\") as f:\n",
    "            writer.write(f)\n",
    "\n",
    "        # í• ë‹¹ëŸ‰ ì—ëŸ¬ ëŒ€ì‘ì„ ìœ„í•œ ì¬ì‹œë„ ë£¨í”„\n",
    "        max_retries = 5\n",
    "        content = \"\"\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            print(f\"ğŸ“„ [{page_num}/{total_pages}] ë¶„ì„ ì¤‘ (ì‹œë„ {attempt+1})...\", end=\"\", flush=True)\n",
    "            try:\n",
    "                # 1ì°¨ ì‹œë„: PDF ì²­í¬ ì§ì ‘ ë¶„ì„\n",
    "                result = await zerox(\n",
    "                    file_path=pdf_chunk_path, \n",
    "                    model=target_model, \n",
    "                    output_dir=doc_dir,\n",
    "                    custom_system_prompt=KOREAN_LAW_PROMPT\n",
    "                )\n",
    "                content = result.pages[0].content if hasattr(result, 'pages') else str(result)\n",
    "                \n",
    "                # ê²°ê³¼ ê²€ì¦ (ë¹„ì–´ìˆê±°ë‚˜ ëª¨ë¸ ê±°ì ˆ ì‹œ)\n",
    "                is_failed = not content.strip() or \"unable to assist\" in content.lower() or \"sorry\" in content.lower()\n",
    "\n",
    "                if is_failed:\n",
    "                    print(\" -> âš ï¸ ì´ë¯¸ì§€ ë³€í™˜ ë³µêµ¬...\", end=\"\", flush=True)\n",
    "                    images = convert_from_path(pdf_path, first_page=page_num, last_page=page_num, dpi=300)\n",
    "                    if images:\n",
    "                        temp_img = f\"recovery_{page_num}.png\"\n",
    "                        images[0].save(temp_img, \"PNG\")\n",
    "                        rec_result = await zerox(\n",
    "                            file_path=temp_img, \n",
    "                            model=target_model,\n",
    "                            custom_system_prompt=KOREAN_LAW_PROMPT\n",
    "                        )\n",
    "                        content = rec_result.pages[0].content if hasattr(rec_result, 'pages') else str(rec_result)\n",
    "                        if os.path.exists(temp_img): os.remove(temp_img)\n",
    "\n",
    "                # ì„±ê³µ ì‹œ ì €ì¥\n",
    "                if content.strip():\n",
    "                    clean_content = content.replace('\\u2022', '-').replace('\\xa0', ' ')\n",
    "                    with open(md_output_path, \"w\", encoding=\"utf-8-sig\", errors=\"replace\") as f:\n",
    "                        f.write(clean_content)\n",
    "                    print(\" -> âœ…\")\n",
    "                    await asyncio.sleep(12) # ì•ˆì •ì ì¸ RPM ìœ ì§€\n",
    "                    break \n",
    "                else:\n",
    "                    raise Exception(\"Empty Content\")\n",
    "\n",
    "            except Exception as e:\n",
    "                error_str = str(e)\n",
    "                if \"429\" in error_str or \"exhausted\" in error_str.lower():\n",
    "                    wait_time = 30 * (attempt + 1)\n",
    "                    print(f\" -> â³ í• ë‹¹ëŸ‰ ì´ˆê³¼! {wait_time}ì´ˆ ëŒ€ê¸°...\")\n",
    "                    await asyncio.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\" -> âŒ ì—ëŸ¬: {error_str[:20]}\")\n",
    "                    await asyncio.sleep(5)\n",
    "                    if attempt == max_retries - 1:\n",
    "                        print(f\" -> ğŸ”´ {page_num}p ìµœì¢… ì‹¤íŒ¨\")\n",
    "\n",
    "        if os.path.exists(pdf_chunk_path):\n",
    "            os.remove(pdf_chunk_path)\n",
    "\n",
    "    print(f\"\\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ! './documents' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# ì£¼í”¼í„° ì‹¤í–‰ë¶€\n",
    "if __name__ == \"__main__\":\n",
    "    await process_income_tax_pdf('./income_tax.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd511c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… page_1.md ë³‘í•© ì™„ë£Œ (1/137)\n",
      "âœ… page_2.md ë³‘í•© ì™„ë£Œ (2/137)\n",
      "âœ… page_3.md ë³‘í•© ì™„ë£Œ (3/137)\n",
      "âœ… page_4.md ë³‘í•© ì™„ë£Œ (4/137)\n",
      "âœ… page_5.md ë³‘í•© ì™„ë£Œ (5/137)\n",
      "âœ… page_6.md ë³‘í•© ì™„ë£Œ (6/137)\n",
      "âœ… page_7.md ë³‘í•© ì™„ë£Œ (7/137)\n",
      "âœ… page_8.md ë³‘í•© ì™„ë£Œ (8/137)\n",
      "âœ… page_9.md ë³‘í•© ì™„ë£Œ (9/137)\n",
      "âœ… page_10.md ë³‘í•© ì™„ë£Œ (10/137)\n",
      "âœ… page_11.md ë³‘í•© ì™„ë£Œ (11/137)\n",
      "âœ… page_12.md ë³‘í•© ì™„ë£Œ (12/137)\n",
      "âœ… page_13.md ë³‘í•© ì™„ë£Œ (13/137)\n",
      "âœ… page_14.md ë³‘í•© ì™„ë£Œ (14/137)\n",
      "âœ… page_15.md ë³‘í•© ì™„ë£Œ (15/137)\n",
      "âœ… page_16.md ë³‘í•© ì™„ë£Œ (16/137)\n",
      "âœ… page_17.md ë³‘í•© ì™„ë£Œ (17/137)\n",
      "âœ… page_18.md ë³‘í•© ì™„ë£Œ (18/137)\n",
      "âœ… page_19.md ë³‘í•© ì™„ë£Œ (19/137)\n",
      "âœ… page_20.md ë³‘í•© ì™„ë£Œ (20/137)\n",
      "âœ… page_21.md ë³‘í•© ì™„ë£Œ (21/137)\n",
      "âœ… page_22.md ë³‘í•© ì™„ë£Œ (22/137)\n",
      "âœ… page_23.md ë³‘í•© ì™„ë£Œ (23/137)\n",
      "âœ… page_24.md ë³‘í•© ì™„ë£Œ (24/137)\n",
      "âœ… page_25.md ë³‘í•© ì™„ë£Œ (25/137)\n",
      "âœ… page_26.md ë³‘í•© ì™„ë£Œ (26/137)\n",
      "âœ… page_27.md ë³‘í•© ì™„ë£Œ (27/137)\n",
      "âœ… page_28.md ë³‘í•© ì™„ë£Œ (28/137)\n",
      "âœ… page_29.md ë³‘í•© ì™„ë£Œ (29/137)\n",
      "âœ… page_30.md ë³‘í•© ì™„ë£Œ (30/137)\n",
      "âœ… page_31.md ë³‘í•© ì™„ë£Œ (31/137)\n",
      "âœ… page_32.md ë³‘í•© ì™„ë£Œ (32/137)\n",
      "âœ… page_33.md ë³‘í•© ì™„ë£Œ (33/137)\n",
      "âœ… page_34.md ë³‘í•© ì™„ë£Œ (34/137)\n",
      "âœ… page_35.md ë³‘í•© ì™„ë£Œ (35/137)\n",
      "âœ… page_36.md ë³‘í•© ì™„ë£Œ (36/137)\n",
      "âœ… page_37.md ë³‘í•© ì™„ë£Œ (37/137)\n",
      "âœ… page_38.md ë³‘í•© ì™„ë£Œ (38/137)\n",
      "âœ… page_39.md ë³‘í•© ì™„ë£Œ (39/137)\n",
      "âœ… page_40.md ë³‘í•© ì™„ë£Œ (40/137)\n",
      "âœ… page_41.md ë³‘í•© ì™„ë£Œ (41/137)\n",
      "âœ… page_42.md ë³‘í•© ì™„ë£Œ (42/137)\n",
      "âœ… page_43.md ë³‘í•© ì™„ë£Œ (43/137)\n",
      "âœ… page_44.md ë³‘í•© ì™„ë£Œ (44/137)\n",
      "âœ… page_45.md ë³‘í•© ì™„ë£Œ (45/137)\n",
      "âœ… page_46.md ë³‘í•© ì™„ë£Œ (46/137)\n",
      "âœ… page_47.md ë³‘í•© ì™„ë£Œ (47/137)\n",
      "âœ… page_48.md ë³‘í•© ì™„ë£Œ (48/137)\n",
      "âœ… page_49.md ë³‘í•© ì™„ë£Œ (49/137)\n",
      "âœ… page_50.md ë³‘í•© ì™„ë£Œ (50/137)\n",
      "âœ… page_51.md ë³‘í•© ì™„ë£Œ (51/137)\n",
      "âœ… page_52.md ë³‘í•© ì™„ë£Œ (52/137)\n",
      "âœ… page_53.md ë³‘í•© ì™„ë£Œ (53/137)\n",
      "âœ… page_54.md ë³‘í•© ì™„ë£Œ (54/137)\n",
      "âœ… page_55.md ë³‘í•© ì™„ë£Œ (55/137)\n",
      "âœ… page_56.md ë³‘í•© ì™„ë£Œ (56/137)\n",
      "âœ… page_57.md ë³‘í•© ì™„ë£Œ (57/137)\n",
      "âœ… page_58.md ë³‘í•© ì™„ë£Œ (58/137)\n",
      "âœ… page_59.md ë³‘í•© ì™„ë£Œ (59/137)\n",
      "âœ… page_60.md ë³‘í•© ì™„ë£Œ (60/137)\n",
      "âœ… page_61.md ë³‘í•© ì™„ë£Œ (61/137)\n",
      "âœ… page_62.md ë³‘í•© ì™„ë£Œ (62/137)\n",
      "âœ… page_63.md ë³‘í•© ì™„ë£Œ (63/137)\n",
      "âœ… page_64.md ë³‘í•© ì™„ë£Œ (64/137)\n",
      "âœ… page_65.md ë³‘í•© ì™„ë£Œ (65/137)\n",
      "âœ… page_66.md ë³‘í•© ì™„ë£Œ (66/137)\n",
      "âœ… page_67.md ë³‘í•© ì™„ë£Œ (67/137)\n",
      "âœ… page_68.md ë³‘í•© ì™„ë£Œ (68/137)\n",
      "âœ… page_69.md ë³‘í•© ì™„ë£Œ (69/137)\n",
      "âœ… page_70.md ë³‘í•© ì™„ë£Œ (70/137)\n",
      "âœ… page_71.md ë³‘í•© ì™„ë£Œ (71/137)\n",
      "âœ… page_72.md ë³‘í•© ì™„ë£Œ (72/137)\n",
      "âœ… page_73.md ë³‘í•© ì™„ë£Œ (73/137)\n",
      "âœ… page_74.md ë³‘í•© ì™„ë£Œ (74/137)\n",
      "âœ… page_75.md ë³‘í•© ì™„ë£Œ (75/137)\n",
      "âœ… page_76.md ë³‘í•© ì™„ë£Œ (76/137)\n",
      "âœ… page_77.md ë³‘í•© ì™„ë£Œ (77/137)\n",
      "âœ… page_78.md ë³‘í•© ì™„ë£Œ (78/137)\n",
      "âœ… page_79.md ë³‘í•© ì™„ë£Œ (79/137)\n",
      "âœ… page_80.md ë³‘í•© ì™„ë£Œ (80/137)\n",
      "âœ… page_81.md ë³‘í•© ì™„ë£Œ (81/137)\n",
      "âœ… page_82.md ë³‘í•© ì™„ë£Œ (82/137)\n",
      "âœ… page_83.md ë³‘í•© ì™„ë£Œ (83/137)\n",
      "âœ… page_84.md ë³‘í•© ì™„ë£Œ (84/137)\n",
      "âœ… page_85.md ë³‘í•© ì™„ë£Œ (85/137)\n",
      "âœ… page_86.md ë³‘í•© ì™„ë£Œ (86/137)\n",
      "âœ… page_87.md ë³‘í•© ì™„ë£Œ (87/137)\n",
      "âœ… page_88.md ë³‘í•© ì™„ë£Œ (88/137)\n",
      "âœ… page_89.md ë³‘í•© ì™„ë£Œ (89/137)\n",
      "âœ… page_90.md ë³‘í•© ì™„ë£Œ (90/137)\n",
      "âœ… page_91.md ë³‘í•© ì™„ë£Œ (91/137)\n",
      "âœ… page_92.md ë³‘í•© ì™„ë£Œ (92/137)\n",
      "âœ… page_93.md ë³‘í•© ì™„ë£Œ (93/137)\n",
      "âœ… page_94.md ë³‘í•© ì™„ë£Œ (94/137)\n",
      "âœ… page_95.md ë³‘í•© ì™„ë£Œ (95/137)\n",
      "âœ… page_96.md ë³‘í•© ì™„ë£Œ (96/137)\n",
      "âœ… page_97.md ë³‘í•© ì™„ë£Œ (97/137)\n",
      "âœ… page_98.md ë³‘í•© ì™„ë£Œ (98/137)\n",
      "âœ… page_99.md ë³‘í•© ì™„ë£Œ (99/137)\n",
      "âœ… page_100.md ë³‘í•© ì™„ë£Œ (100/137)\n",
      "âœ… page_101.md ë³‘í•© ì™„ë£Œ (101/137)\n",
      "âœ… page_102.md ë³‘í•© ì™„ë£Œ (102/137)\n",
      "âœ… page_103.md ë³‘í•© ì™„ë£Œ (103/137)\n",
      "âœ… page_104.md ë³‘í•© ì™„ë£Œ (104/137)\n",
      "âœ… page_105.md ë³‘í•© ì™„ë£Œ (105/137)\n",
      "âœ… page_106.md ë³‘í•© ì™„ë£Œ (106/137)\n",
      "âœ… page_107.md ë³‘í•© ì™„ë£Œ (107/137)\n",
      "âœ… page_108.md ë³‘í•© ì™„ë£Œ (108/137)\n",
      "âœ… page_109.md ë³‘í•© ì™„ë£Œ (109/137)\n",
      "âœ… page_110.md ë³‘í•© ì™„ë£Œ (110/137)\n",
      "âœ… page_111.md ë³‘í•© ì™„ë£Œ (111/137)\n",
      "âœ… page_112.md ë³‘í•© ì™„ë£Œ (112/137)\n",
      "âœ… page_113.md ë³‘í•© ì™„ë£Œ (113/137)\n",
      "âœ… page_114.md ë³‘í•© ì™„ë£Œ (114/137)\n",
      "âœ… page_115.md ë³‘í•© ì™„ë£Œ (115/137)\n",
      "âœ… page_116.md ë³‘í•© ì™„ë£Œ (116/137)\n",
      "âœ… page_117.md ë³‘í•© ì™„ë£Œ (117/137)\n",
      "âœ… page_118.md ë³‘í•© ì™„ë£Œ (118/137)\n",
      "âœ… page_119.md ë³‘í•© ì™„ë£Œ (119/137)\n",
      "âœ… page_120.md ë³‘í•© ì™„ë£Œ (120/137)\n",
      "âœ… page_121.md ë³‘í•© ì™„ë£Œ (121/137)\n",
      "âœ… page_122.md ë³‘í•© ì™„ë£Œ (122/137)\n",
      "âœ… page_123.md ë³‘í•© ì™„ë£Œ (123/137)\n",
      "âœ… page_124.md ë³‘í•© ì™„ë£Œ (124/137)\n",
      "âœ… page_125.md ë³‘í•© ì™„ë£Œ (125/137)\n",
      "âœ… page_126.md ë³‘í•© ì™„ë£Œ (126/137)\n",
      "âœ… page_127.md ë³‘í•© ì™„ë£Œ (127/137)\n",
      "âœ… page_128.md ë³‘í•© ì™„ë£Œ (128/137)\n",
      "âœ… page_129.md ë³‘í•© ì™„ë£Œ (129/137)\n",
      "âœ… page_130.md ë³‘í•© ì™„ë£Œ (130/137)\n",
      "âœ… page_131.md ë³‘í•© ì™„ë£Œ (131/137)\n",
      "âœ… page_132.md ë³‘í•© ì™„ë£Œ (132/137)\n",
      "âœ… page_133.md ë³‘í•© ì™„ë£Œ (133/137)\n",
      "âœ… page_134.md ë³‘í•© ì™„ë£Œ (134/137)\n",
      "âœ… page_135.md ë³‘í•© ì™„ë£Œ (135/137)\n",
      "âœ… page_136.md ë³‘í•© ì™„ë£Œ (136/137)\n",
      "âœ… page_137.md ë³‘í•© ì™„ë£Œ (137/137)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def combine_markdown_files(source_dir, output_file):\n",
    "    # 1. íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ë° ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ìì—°ì–´ ì •ë ¬)\n",
    "    # page_1, page_2, ..., page_10 ìˆœì„œë¡œ ì •ë ¬ë˜ë„ë¡ ìˆ˜ì •\n",
    "    def extract_number(f):\n",
    "        numbers = re.findall(r'\\d+', f)\n",
    "        return int(numbers[0]) if numbers else 0\n",
    "\n",
    "    md_files = [f for f in os.listdir(source_dir) if f.endswith('.md')]\n",
    "    md_files.sort(key=extract_number)\n",
    "    \n",
    "    # 2. ê²°ê³¼ íŒŒì¼ ì‘ì„± (ê¸°ë³¸ì ìœ¼ë¡œ UTF-8 ê¶Œì¥, ì—‘ì…€/í•œê¸€ìš©ì´ë©´ euc-kr ì‚¬ìš©)\n",
    "    # ì—¬ê¸°ì„œëŠ” zerox ê²°ê³¼ ë³´ì¡´ì„ ìœ„í•´ utf-8-sigë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    with open(output_file, 'w', encoding='utf-8-sig') as outfile:\n",
    "        total = len(md_files)\n",
    "        \n",
    "        for i, filename in enumerate(md_files):\n",
    "            file_path = os.path.join(source_dir, filename)\n",
    "            \n",
    "            # ì´ì „ ë‹¨ê³„ ì €ì¥ ê·œê²©ì¸ utf-8-sigë¡œ ì½ê¸°\n",
    "            with open(file_path, 'r', encoding='utf-8-sig', errors='ignore') as infile:\n",
    "                content = infile.read()\n",
    "                \n",
    "                # íŒŒì¼ êµ¬ë¶„ì„  ë° í˜ì´ì§€ ì •ë³´ ì¶”ê°€\n",
    "                outfile.write(f\"\\n\\n\\n\") \n",
    "                outfile.write(content)\n",
    "                outfile.write(\"\\n\\n---\\n\\n\")\n",
    "            \n",
    "            print(f\"âœ… {filename} ë³‘í•© ì™„ë£Œ ({i+1}/{total})\")\n",
    "\n",
    "# ì‹¤í–‰ ì„¤ì •\n",
    "source_directory = \"./documents\"   \n",
    "combined_filename = \"tax_combined_final.md\" \n",
    "\n",
    "combine_markdown_files(source_directory, combined_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1c081ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"unstructured[md]\" nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8294d986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './tax_combined_final.md'}, page_content='ì œ54ì¡°ì˜2(ê³µë™ì‚¬ì—…ì— ëŒ€í•œ ì†Œë“ê³µì œ ë“± íŠ¹ë¡€) ì œ51ì¡°ì˜3 ë˜ëŠ” ã€Œì¡°ì„¸íŠ¹ë¡€ì œí•œë²•ã€ì— ë”°ë¥¸ ì†Œë“ê³µì œë¥¼ ì ìš©í•˜ê±°ë‚˜ ì œ59ì¡°ì˜3ì— ë”°ë¥¸ ì„¸ì•¡ê³µì œë¥¼ ì ìš©í•˜ëŠ” ê²½ìš° ì œ43ì¡°ì œ3í•­ì— ë”°ë¼ ì†Œë“ê¸ˆì•¡ì´ ì£¼ëœ ê³µë™ì‚¬ì—…ìì˜ ì†Œë“ê¸ˆì•¡ì— í•©ì‚°ê³¼ì„¸ë˜ëŠ” íŠ¹ìˆ˜ê´€ê³„ì¸ì´ ì§€ì¶œÂ·ë‚©ì…Â·íˆ¬ìÂ·ì¶œì ë“±ì„ í•œ ê¸ˆì•¡ì´ ìˆìœ¼ë©´ ì£¼ëœ ê³µë™ì‚¬ì—…ìì˜ ì†Œë“ì— í•©ì‚°ê³¼ì„¸ë˜ëŠ” ì†Œë“ê¸ˆì•¡ì˜ í•œë„ì—ì„œ ì£¼ëœ ê³µë™ì‚¬ì—…ìê°€ ì§€ì¶œÂ·ë‚©ì…Â·íˆ¬ìÂ·ì¶œì ë“±ì„ í•œ ê¸ˆì•¡ìœ¼ë¡œ ë³´ì•„ ì£¼ëœ ê³µë™ì‚¬ì—…ìì˜ í•©ì‚°ê³¼ì„¸ë˜ëŠ” ì¢…í•©ì†Œë“ê¸ˆì•¡ ë˜ëŠ” ì¢…í•©ì†Œë“ì‚°ì¶œì„¸ì•¡ì„ ê³„ì‚°í•  ë•Œì— ì†Œë“ê³µì œ ë˜ëŠ” ì„¸ì•¡ê³µì œë¥¼ ë°›ì„ ìˆ˜ ìˆë‹¤. <ê°œì • 2012. 1. 1., 2014. 1. 1.> [ì „ë¬¸ê°œì • 2009. 12. 31.] [ì œëª©ê°œì • 2014. 1. 1.]\\n\\nì œ4ì ˆ ì„¸ì•¡ì˜ ê³„ì‚° <ê°œì • 2009. 12. 31.> ì œ1ê´€ ì„¸ìœ¨ <ê°œì • 2009. 12. 31.> ì œ55ì¡°(ì„¸ìœ¨) â‘ ê±°ì£¼ìì˜ ì¢…í•©ì†Œë“ì— ëŒ€í•œ ì†Œë“ì„¸ëŠ” í•´ë‹¹ ì—°ë„ì˜ ì¢…í•©ì†Œë“ê³¼ì„¸í‘œì¤€ì— ë‹¤ìŒì˜ ì„¸ìœ¨ì„ ì ìš©í•˜ì—¬ ê³„ì‚°í•œ ê¸ˆì•¡(ì´í•˜ \"ì¢…í•©ì†Œë“ì‚°ì¶œì„¸ì•¡\"ì´ë¼ í•œë‹¤)ì„ ê·¸ ì„¸ì•¡ìœ¼ë¡œ í•œë‹¤. <ê°œì • 2014. 1. 1., 2016. 12. 20., 2017. 12. 19., 2020. 12. 29., 2022. 12. 31.>\\n\\nì¢…í•©ì†Œë“ ê³¼ì„¸í‘œì¤€ ì„¸ìœ¨ 1,400ë§Œì› ì´í•˜ ê³¼ì„¸í‘œì¤€ì˜ 6í¼ì„¼íŠ¸ 1,400ë§Œì› ì´ˆê³¼ 84ë§Œì› + (1,400ë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 15í¼ì„¼íŠ¸) 5,000ë§Œì› ì´í•˜ 5,000ë§Œì› ì´ˆê³¼ 624ë§Œì› + (5,000ë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 24í¼ì„¼íŠ¸) 8,800ë§Œì› ì´í•˜ 8,800ë§Œì› ì´ˆê³¼ 1,536ë§Œì› + (8,800ë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 35í¼ì„¼íŠ¸) 1ì–µ5ì²œë§Œì› ì´í•˜ 1ì–µ5ì²œë§Œì› ì´ˆê³¼ 3,706ë§Œì› + (1ì–µ5ì²œë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 38í¼ì„¼íŠ¸) 3ì–µì› ì´í•˜ 3ì–µì› ì´ˆê³¼ 9,406ë§Œì› + (3ì–µì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 40í¼ì„¼íŠ¸) 5ì–µì› ì´í•˜ 5ì–µì› ì´ˆê³¼ 1ì–µ7,406ë§Œì› + (5ì–µì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 42í¼ì„¼íŠ¸) 10ì–µì› ì´í•˜ 10ì–µì› ì´ˆê³¼ 3ì–µ8,406ë§Œì› + (10ì–µì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 45í¼ì„¼íŠ¸)\\n\\nâ‘¡ ê±°ì£¼ìì˜ í‡´ì§ì†Œë“ì— ëŒ€í•œ ì†Œë“ì„¸ëŠ” ë‹¤ìŒ ê° í˜¸ì˜ ìˆœì„œì— ë”°ë¼ ê³„ì‚°í•œ ê¸ˆì•¡(ì´í•˜ \"í‡´ì§ì†Œë“ ì‚°ì¶œì„¸ì•¡\"ì´ë¼ í•œë‹¤)ìœ¼ë¡œ í•œë‹¤. <ê°œì • 2013. 1. 1., 2014. 12. 23.> 1. í•´ë‹¹ ê³¼ì„¸ê¸°ê°„ì˜ í‡´ì§ì†Œë“ê³¼ì„¸í‘œì¤€ì— ì œ1í•­ì˜ ì„¸ìœ¨ì„ ì ìš©í•˜ì—¬ ê³„ì‚°í•œ ê¸ˆì•¡ 2. ì œ1í˜¸ì˜ ê¸ˆì•¡ì„ 12ë¡œ ë‚˜ëˆˆ ê¸ˆì•¡ì— ê·¼ì†ì—°ìˆ˜ë¥¼ ê³±í•œ ê¸ˆì•¡ 3. ì‚­ì œ <2014. 12. 23.> [ì „ë¬¸ê°œì • 2009. 12. 31.]\\n\\nì œ2ê´€ ì„¸ì•¡ê³µì œ <ê°œì • 2009. 12. 31.>')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_list[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9922902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# 1. Load the raw markdown text using TextLoader (UnstructuredMarkdownLoader strips headers)\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loader = UnstructuredMarkdownLoader(\n",
    "    \"./tax_combined_final.md\",\n",
    "    mode=\"single\",\n",
    "    strategy=\"fast\",\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)\n",
    "\n",
    "# 'sections' is now a list of Documents, each with metadata indicating its headers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb34d46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìƒì„±ëœ ì²­í¬ ê°œìˆ˜: 240\n",
      "âœ… ì²« ë²ˆì§¸ ì²­í¬ ë‚´ìš© í™•ì¸: ì†Œë“ì„¸ë²•\n",
      "\n",
      "ì†Œë“ì„¸ë²• [ì‹œí–‰ 2026. 1. 2.] [ë²•ë¥  ì œ21065í˜¸, 2025. 10. 1., íƒ€ë²•ê°œì •] ê¸°íšì¬ì •ë¶€(ì¬ì‚°ì„¸ì œê³¼(ì–‘ë„ì†Œë“ì„¸)) 044-215-4312 ê¸°íšì¬ì •ë¶€ \n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"âœ… ìƒì„±ëœ ì²­í¬ ê°œìˆ˜: {len(texts)}\")\n",
    "print(f\"âœ… ì²« ë²ˆì§¸ ì²­í¬ ë‚´ìš© í™•ì¸: {texts[0].page_content[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a074428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './tax_combined_final.md'}, page_content='ì œ54ì¡°ì˜2(ê³µë™ì‚¬ì—…ì— ëŒ€í•œ ì†Œë“ê³µì œ ë“± íŠ¹ë¡€) ì œ51ì¡°ì˜3 ë˜ëŠ” ã€Œì¡°ì„¸íŠ¹ë¡€ì œí•œë²•ã€ì— ë”°ë¥¸ ì†Œë“ê³µì œë¥¼ ì ìš©í•˜ê±°ë‚˜ ì œ59ì¡°ì˜3ì— ë”°ë¥¸ ì„¸ì•¡ê³µì œë¥¼ ì ìš©í•˜ëŠ” ê²½ìš° ì œ43ì¡°ì œ3í•­ì— ë”°ë¼ ì†Œë“ê¸ˆì•¡ì´ ì£¼ëœ ê³µë™ì‚¬ì—…ìì˜ ì†Œë“ê¸ˆì•¡ì— í•©ì‚°ê³¼ì„¸ë˜ëŠ” íŠ¹ìˆ˜ê´€ê³„ì¸ì´ ì§€ì¶œÂ·ë‚©ì…Â·íˆ¬ìÂ·ì¶œì ë“±ì„ í•œ ê¸ˆì•¡ì´ ìˆìœ¼ë©´ ì£¼ëœ ê³µë™ì‚¬ì—…ìì˜ ì†Œë“ì— í•©ì‚°ê³¼ì„¸ë˜ëŠ” ì†Œë“ê¸ˆì•¡ì˜ í•œë„ì—ì„œ ì£¼ëœ ê³µë™ì‚¬ì—…ìê°€ ì§€ì¶œÂ·ë‚©ì…Â·íˆ¬ìÂ·ì¶œì ë“±ì„ í•œ ê¸ˆì•¡ìœ¼ë¡œ ë³´ì•„ ì£¼ëœ ê³µë™ì‚¬ì—…ìì˜ í•©ì‚°ê³¼ì„¸ë˜ëŠ” ì¢…í•©ì†Œë“ê¸ˆì•¡ ë˜ëŠ” ì¢…í•©ì†Œë“ì‚°ì¶œì„¸ì•¡ì„ ê³„ì‚°í•  ë•Œì— ì†Œë“ê³µì œ ë˜ëŠ” ì„¸ì•¡ê³µì œë¥¼ ë°›ì„ ìˆ˜ ìˆë‹¤. <ê°œì • 2012. 1. 1., 2014. 1. 1.> [ì „ë¬¸ê°œì • 2009. 12. 31.] [ì œëª©ê°œì • 2014. 1. 1.]\\n\\nì œ4ì ˆ ì„¸ì•¡ì˜ ê³„ì‚° <ê°œì • 2009. 12. 31.> ì œ1ê´€ ì„¸ìœ¨ <ê°œì • 2009. 12. 31.> ì œ55ì¡°(ì„¸ìœ¨) â‘ ê±°ì£¼ìì˜ ì¢…í•©ì†Œë“ì— ëŒ€í•œ ì†Œë“ì„¸ëŠ” í•´ë‹¹ ì—°ë„ì˜ ì¢…í•©ì†Œë“ê³¼ì„¸í‘œì¤€ì— ë‹¤ìŒì˜ ì„¸ìœ¨ì„ ì ìš©í•˜ì—¬ ê³„ì‚°í•œ ê¸ˆì•¡(ì´í•˜ \"ì¢…í•©ì†Œë“ì‚°ì¶œì„¸ì•¡\"ì´ë¼ í•œë‹¤)ì„ ê·¸ ì„¸ì•¡ìœ¼ë¡œ í•œë‹¤. <ê°œì • 2014. 1. 1., 2016. 12. 20., 2017. 12. 19., 2020. 12. 29., 2022. 12. 31.>\\n\\nì¢…í•©ì†Œë“ ê³¼ì„¸í‘œì¤€ ì„¸ìœ¨ 1,400ë§Œì› ì´í•˜ ê³¼ì„¸í‘œì¤€ì˜ 6í¼ì„¼íŠ¸ 1,400ë§Œì› ì´ˆê³¼ 84ë§Œì› + (1,400ë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 15í¼ì„¼íŠ¸) 5,000ë§Œì› ì´í•˜ 5,000ë§Œì› ì´ˆê³¼ 624ë§Œì› + (5,000ë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 24í¼ì„¼íŠ¸) 8,800ë§Œì› ì´í•˜ 8,800ë§Œì› ì´ˆê³¼ 1,536ë§Œì› + (8,800ë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 35í¼ì„¼íŠ¸) 1ì–µ5ì²œë§Œì› ì´í•˜ 1ì–µ5ì²œë§Œì› ì´ˆê³¼ 3,706ë§Œì› + (1ì–µ5ì²œë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 38í¼ì„¼íŠ¸) 3ì–µì› ì´í•˜ 3ì–µì› ì´ˆê³¼ 9,406ë§Œì› + (3ì–µì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 40í¼ì„¼íŠ¸) 5ì–µì› ì´í•˜ 5ì–µì› ì´ˆê³¼ 1ì–µ7,406ë§Œì› + (5ì–µì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 42í¼ì„¼íŠ¸) 10ì–µì› ì´í•˜ 10ì–µì› ì´ˆê³¼ 3ì–µ8,406ë§Œì› + (10ì–µì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 45í¼ì„¼íŠ¸)\\n\\nâ‘¡ ê±°ì£¼ìì˜ í‡´ì§ì†Œë“ì— ëŒ€í•œ ì†Œë“ì„¸ëŠ” ë‹¤ìŒ ê° í˜¸ì˜ ìˆœì„œì— ë”°ë¼ ê³„ì‚°í•œ ê¸ˆì•¡(ì´í•˜ \"í‡´ì§ì†Œë“ ì‚°ì¶œì„¸ì•¡\"ì´ë¼ í•œë‹¤)ìœ¼ë¡œ í•œë‹¤. <ê°œì • 2013. 1. 1., 2014. 12. 23.> 1. í•´ë‹¹ ê³¼ì„¸ê¸°ê°„ì˜ í‡´ì§ì†Œë“ê³¼ì„¸í‘œì¤€ì— ì œ1í•­ì˜ ì„¸ìœ¨ì„ ì ìš©í•˜ì—¬ ê³„ì‚°í•œ ê¸ˆì•¡ 2. ì œ1í˜¸ì˜ ê¸ˆì•¡ì„ 12ë¡œ ë‚˜ëˆˆ ê¸ˆì•¡ì— ê·¼ì†ì—°ìˆ˜ë¥¼ ê³±í•œ ê¸ˆì•¡ 3. ì‚­ì œ <2014. 12. 23.> [ì „ë¬¸ê°œì • 2009. 12. 31.]\\n\\nì œ2ê´€ ì„¸ì•¡ê³µì œ <ê°œì • 2009. 12. 31.>')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5576464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q markdown html2text beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d575ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown converted to plain text successfully!\n"
     ]
    }
   ],
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "text_path = './tax_combined_final.txt'\n",
    "markdown_path= './tax_combined_final.md'\n",
    "# ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤\n",
    "with open(markdown_path, 'r', encoding='utf-8') as md_file:\n",
    "    md_content = md_file.read()\n",
    "\n",
    "# ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ ë¥¼ HTMLë¡œ ë³€í™˜í•©ë‹ˆë‹¤\n",
    "html_content = markdown.markdown(md_content)\n",
    "\n",
    "# HTML ì½˜í…ì¸ ë¥¼ íŒŒì‹±í•˜ì—¬ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "text_content = soup.get_text()\n",
    "\n",
    "# ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤\n",
    "with open(text_path, 'w', encoding='utf-8') as txt_file:\n",
    "    txt_file.write(text_content)\n",
    "\n",
    "print(\"Markdown converted to plain text successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "863c60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# encoding=\"utf-8-sig\"ë¥¼ ë°˜ë“œì‹œ ì¶”ê°€í•˜ì„¸ìš”\n",
    "loader = TextLoader(\"./tax_combined_final.txt\", encoding=\"utf-8-sig\")\n",
    "document_list = loader.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0aca5fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './tax_combined_final.txt'}, page_content='ì¢…í•©ì†Œë“\\nê³¼ì„¸í‘œì¤€\\nì„¸ìœ¨\\n1,400ë§Œì› ì´í•˜\\nê³¼ì„¸í‘œì¤€ì˜ 6í¼ì„¼íŠ¸\\n1,400ë§Œì› ì´ˆê³¼\\n84ë§Œì› + (1,400ë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 15í¼ì„¼íŠ¸)\\n5,000ë§Œì› ì´í•˜\\n5,000ë§Œì› ì´ˆê³¼\\n624ë§Œì› + (5,000ë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 24í¼ì„¼íŠ¸)\\n8,800ë§Œì› ì´í•˜\\n8,800ë§Œì› ì´ˆê³¼\\n1,536ë§Œì› + (8,800ë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 35í¼ì„¼íŠ¸)\\n1ì–µ5ì²œë§Œì› ì´í•˜\\n1ì–µ5ì²œë§Œì› ì´ˆê³¼\\n3,706ë§Œì› + (1ì–µ5ì²œë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 38í¼ì„¼íŠ¸)\\n3ì–µì› ì´í•˜\\n3ì–µì› ì´ˆê³¼\\n9,406ë§Œì› + (3ì–µì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 40í¼ì„¼íŠ¸)\\n5ì–µì› ì´í•˜\\n5ì–µì› ì´ˆê³¼\\n1ì–µ7,406ë§Œì› + (5ì–µì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 42í¼ì„¼íŠ¸)\\n10ì–µì› ì´í•˜\\n10ì–µì› ì´ˆê³¼\\n3ì–µ8,406ë§Œì› + (10ì–µì›ì„ ì´ˆê³¼í•˜ëŠ” ê¸ˆì•¡ì˜ 45í¼ì„¼íŠ¸)\\nâ‘¡ ê±°ì£¼ìì˜ í‡´ì§ì†Œë“ì— ëŒ€í•œ ì†Œë“ì„¸ëŠ” ë‹¤ìŒ ê° í˜¸ì˜ ìˆœì„œì— ë”°ë¼ ê³„ì‚°í•œ ê¸ˆì•¡(ì´í•˜ \"í‡´ì§ì†Œë“ ì‚°ì¶œì„¸ì•¡\"ì´ë¼ í•œë‹¤)ìœ¼ë¡œ í•œë‹¤. <ê°œì • 2013. 1. 1., 2014. 12. 23.>\\n1. í•´ë‹¹ ê³¼ì„¸ê¸°ê°„ì˜ í‡´ì§ì†Œë“ê³¼ì„¸í‘œì¤€ì— ì œ1í•­ì˜ ì„¸ìœ¨ì„ ì ìš©í•˜ì—¬ ê³„ì‚°í•œ ê¸ˆì•¡\\n2. ì œ1í˜¸ì˜ ê¸ˆì•¡ì„ 12ë¡œ ë‚˜ëˆˆ ê¸ˆì•¡ì— ê·¼ì†ì—°ìˆ˜ë¥¼ ê³±í•œ ê¸ˆì•¡\\n3. ì‚­ì œ <2014. 12. 23.>\\n[ì „ë¬¸ê°œì • 2009. 12. 31.]\\nì œ2ê´€ ì„¸ì•¡ê³µì œ <ê°œì • 2009. 12. 31.>\\nì œ56ì¡°(ë°°ë‹¹ì„¸ì•¡ê³µì œ) â‘  ê±°ì£¼ìì˜ ì¢…í•©ì†Œë“ê¸ˆì•¡ì— ì œ17ì¡°ì œ3í•­ ê° í˜¸ ì™¸ì˜ ë¶€ë¶„ ë‹¨ì„œê°€ ì ìš©ë˜ëŠ” ë°°ë‹¹ì†Œë“ê¸ˆì•¡ì´ í•©ì‚°ë˜ì–´ ìˆëŠ” ê²½ìš°ì—ëŠ” ê°™ì€ í•­ ê° í˜¸ ì™¸ì˜ ë¶€ë¶„ ë‹¨ì„œì— ë”°ë¼ í•´ë‹¹ ê³¼ì„¸ê¸°ê°„ì˜ ì´ìˆ˜ì…ê¸ˆì•¡ì— ë”í•œ ê¸ˆì•¡ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ì„ ì¢…í•©ì†Œë“ ì‚°ì¶œì„¸ì•¡ì—ì„œ ê³µì œí•œë‹¤. <ê°œì • 2009. 12. 31.>\\nâ‘¡ ì œ1í•­ì— ë”°ë¥¸ ê³µì œë¥¼ \"ë°°ë‹¹ì„¸ì•¡ê³µì œ\"ë¼ í•œë‹¤. <ê°œì • 2009. 12. 31.>\\nâ‘¢ ì‚­ì œ<2003. 12. 30.>\\nâ‘£ ì œ1í•­ì„ ì ìš©í•  ë•Œ ë°°ë‹¹ì„¸ì•¡ê³µì œì˜ ëŒ€ìƒì´ ë˜ëŠ” ë°°ë‹¹ì†Œë“ê¸ˆì•¡ì€ ì œ14ì¡°ì œ2í•­ì˜ ì¢…í•©ì†Œë“ê³¼ì„¸í‘œì¤€ì— í¬í•¨ëœ ë°°ë‹¹ì†Œë“ê¸ˆì•¡ìœ¼ë¡œì„œ ì´ìì†Œë“ë“±ì˜ ì¢…í•©ê³¼ì„¸ê¸°ì¤€ê¸ˆì•¡ì„ ì´ˆê³¼í•˜ëŠ” ê²ƒìœ¼ë¡œ í•œë‹¤. <ê°œì • 2009. 12. 31.>\\nâ‘¤ ì‚­ì œ<2006. 12. 30.>\\nâ‘¥ ë°°ë‹¹ì„¸ì•¡ê³µì œì•¡ì˜ ê³„ì‚° ë“±ì— í•„ìš”í•œ ì‚¬í•­ì€ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•œë‹¤. <ê°œì • 2009. 12. 31.>\\n[ì œëª©ê°œì • 2009. 12. 31.]\\nì œ56ì¡°ì˜2(ê¸°ì¥ì„¸ì•¡ê³µì œ) â‘  ì œ160ì¡°ì œ3í•­ì— ë”°ë¥¸ ê°„í¸ì¥ë¶€ëŒ€ìƒìê°€ ì œ70ì¡° ë˜ëŠ” ì œ74ì¡°ì— ë”°ë¥¸ ê³¼ì„¸í‘œì¤€í™•ì •ì‹ ê³ ë¥¼ í•  ë•Œ ë³µì‹ë¶€ê¸°ì— ë”°ë¼ ê¸°ì¥(ê¸°ì¥)í•˜ì—¬ ì†Œë“ê¸ˆì•¡ì„ ê³„ì‚°í•˜ê³  ì œ70ì¡°ì œ4í•­ì œ3í˜¸ì— ë”°ë¥¸ ì„œë¥˜ë¥¼ ì œì¶œí•˜ëŠ” ê²½ìš°ì—ëŠ” í•´ë‹¹ ì¥ë¶€ì— ì˜í•˜ì—¬ ê³„ì‚°í•œ ì‚¬ì—…ì†Œë“ê¸ˆì•¡ì´ ì¢…í•©ì†Œë“ê¸ˆì•¡ì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ì„ ì¢…í•©ì†Œë“ ì‚°ì¶œì„¸ì•¡ì— ê³±í•˜ì—¬ ê³„ì‚°í•œ ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ì„ ì¢…í•©ì†Œë“ ì‚°ì¶œì„¸ì•¡ì—ì„œ ê³µì œí•œë‹¤. ë‹¤ë§Œ, ê³µì œì„¸ì•¡ì´ 100ë§Œì›ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš°ì—ëŠ” 100ë§Œì›ì„ ê³µì œí•œë‹¤.\\nâ‘¡ ë‹¤ìŒ ê° í˜¸ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ê²½ìš°ì—ëŠ” ì œ1í•­ì— ë”°ë¥¸ ê³µì œ[ì´í•˜ \"ê¸°ì¥ì„¸ì•¡ê³µì œ\"(ê¸°ì¥ì„¸ì•¡ê³µì œ)ë¼ í•œë‹¤]ë¥¼ ì ìš©í•˜ì§€ ì•„ë‹ˆí•œë‹¤.\\n\\nì†Œë“ì„¸ë²•')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_list[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d25963e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain_openai) (1.2.7)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain_openai) (2.15.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain_openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2026.1.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain_openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain_openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: langchain_openai\n",
      "Successfully installed langchain_openai-1.1.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "37a42967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b855116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8a7579dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain_pinecone\n",
      "  Using cached langchain_pinecone-0.2.13-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pinecone\n",
      "  Downloading pinecone-8.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.34 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain_pinecone) (1.2.7)\n",
      "  Using cached pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy!=2.0.2,>=1.26.4 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain_pinecone) (2.4.1)\n",
      "Requirement already satisfied: langchain-openai>=0.3.11 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain_pinecone) (1.1.7)\n",
      "Requirement already satisfied: httpx>=0.28.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain_pinecone) (0.28.1)\n",
      "Collecting simsimd>=5.9.11 (from langchain_pinecone)\n",
      "  Downloading simsimd-6.5.12-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: pydantic>=2.11.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain_pinecone) (2.12.5)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (2026.1.4)\n",
      "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone)\n",
      "  Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (4.15.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (2.6.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.28.0->langchain_pinecone) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.28.0->langchain_pinecone) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.28.0->langchain_pinecone) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx>=0.28.0->langchain_pinecone) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=0.3.34->langchain_pinecone) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=0.3.34->langchain_pinecone) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=0.3.34->langchain_pinecone) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=0.3.34->langchain_pinecone) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=0.3.34->langchain_pinecone) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<2.0.0,>=0.3.34->langchain_pinecone) (0.14.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-openai>=0.3.11->langchain_pinecone) (2.15.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-openai>=0.3.11->langchain_pinecone) (0.12.0)\n",
      "Collecting packaging<26.0.0,>=23.2.0 (from langchain-core<2.0.0,>=0.3.34->langchain_pinecone)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.5)\n",
      "Requirement already satisfied: aiohttp>=3.9.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (3.13.3)\n",
      "Collecting aiohttp-retry<3.0.0,>=2.9.1 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone)\n",
      "  Using cached aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic>=2.11.1->langchain_pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic>=2.11.1->langchain_pinecone) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic>=2.11.1->langchain_pinecone) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.22.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.34->langchain_pinecone) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.34->langchain_pinecone) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.34->langchain_pinecone) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.34->langchain_pinecone) (0.25.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain_pinecone) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain_pinecone) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain_pinecone) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain_pinecone) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai>=0.3.11->langchain_pinecone) (2026.1.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain_pinecone) (0.4.6)\n",
      "Using cached langchain_pinecone-0.2.13-py3-none-any.whl (26 kB)\n",
      "Using cached pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
      "Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl (259 kB)\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading simsimd-6.5.12-cp312-cp312-win_amd64.whl (87 kB)\n",
      "Using cached aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: simsimd, pinecone-plugin-interface, packaging, pinecone-plugin-assistant, pinecone, aiohttp-retry, langchain_pinecone\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed aiohttp-retry-2.9.1 langchain_pinecone-0.2.13 packaging-24.2 pinecone-7.3.0 pinecone-plugin-assistant-1.8.0 pinecone-plugin-interface-0.0.7 simsimd-6.5.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_pinecone pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bd2ca1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "index_name = \"tax-index-langgraph\"\n",
    "\n",
    "vectorstore_from_docs = PineconeVectorStore.from_documents(document_list, index_name=index_name, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d017cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x00000261B3149670>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore_from_docs.as_retriever(search_kwargs={'k':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "acdba232",
   "metadata": {},
   "outputs": [],
   "source": [
    "query= 'ì—°ë´‰ 5ì²œë§Œì› ì§ì¥ì¸ì˜ ì†Œë“ì„¸ëŠ”?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "eaaea73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5a211886-c6db-4fd5-9e77-a4375dd2ee6d', metadata={'source': './tax_combined_final.txt'}, page_content='5. ê³µì ì—°ê¸ˆì†Œë“ì— ëŒ€í•´ì„œëŠ” ê¸°ë³¸ì„¸ìœ¨\\n5ì˜2.ì œ20ì¡°ì˜3ì œ1í•­ì œ2í˜¸ë‚˜ëª© ë° ë‹¤ëª©ì— ë”°ë¥¸ ì—°ê¸ˆê³„ì¢Œ ë‚©ì…ì•¡ì´ë‚˜ ìš´ìš©ì‹¤ì ì— ë”°ë¼ ì¦ê°€ëœ ê¸ˆì•¡ì„ ì—°ê¸ˆìˆ˜ë ¹í•œ\\nì—°ê¸ˆì†Œë“ì— ëŒ€í•´ì„œëŠ” ë‹¤ìŒ ê° ëª©ì˜ êµ¬ë¶„ì— ë”°ë¥¸ ì„¸ìœ¨. ì´ ê²½ìš° ê° ëª©ì˜ ìš”ê±´ì„ ë™ì‹œì— ì¶©ì¡±í•˜ëŠ” ë•Œì—ëŠ” ë‚®ì€ ì„¸ìœ¨\\nì„ ì ìš©í•œë‹¤.\\nê°€. ì—°ê¸ˆì†Œë“ìì˜ ë‚˜ì´ì— ë”°ë¥¸ ë‹¤ìŒì˜ ì„¸ìœ¨\\n|ë‚˜ì´(ì—°ê¸ˆìˆ˜ë ¹ì¼ í˜„ì¬)| ì„¸ìœ¨   |\\n| ----------- | ----------- |\\n| 70ì„¸ ë¯¸ë§Œ | 100ë¶„ì˜ 5 |\\n| 70ì„¸ ì´ìƒ 80ì„¸ ë¯¸ë§Œ | 100ë¶„ì˜ 4 |\\n| 80ì„¸ ì´ìƒ | 100ë¶„ì˜ 3 |\\në‚˜. ì‚­ì œ <2014. 12. 23.>'),\n",
       " Document(id='a6c9015f-092f-4aa3-819b-e23588bb0a0f', metadata={'source': './tax_combined_final.txt'}, page_content='ì†Œë“ì„¸ë²•\\ní•˜ëŠ” ì(ì œ119ì¡°ì œ9í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ë¶€ë™ì‚°ë“±ì–‘ë„ì†Œë“ì„ ì§€ê¸‰í•˜ëŠ” ê±°ì£¼ì ë° ë¹„ê±°ì£¼ìëŠ” ì œì™¸í•œë‹¤)ëŠ” ì œ127ì¡°\\nì—ë„ ë¶ˆêµ¬í•˜ê³  ê·¸ ì†Œë“ì„ ì§€ê¸‰í•  ë•Œì— ë‹¤ìŒ ê° í˜¸ì˜ ê¸ˆì•¡ì„ ê·¸ ë¹„ê±°ì£¼ìì˜ êµ­ë‚´ì›ì²œì†Œë“ì— ëŒ€í•œ ì†Œë“ì„¸ë¡œì„œ ì›ì²œì§•\\nìˆ˜í•˜ì—¬ ê·¸ ì›ì²œì§•ìˆ˜í•œ ë‚ ì´ ì†í•˜ëŠ” ë‹¬ì˜ ë‹¤ìŒ ë‹¬ 10ì¼ê¹Œì§€ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ë°”ì— ë”°ë¼ ì›ì²œì§•ìˆ˜ ê´€í•  ì„¸ë¬´ì„œ,\\ní•œêµ­ì€í–‰ ë˜ëŠ” ì²´ì‹ ê´€ì„œì— ë‚©ë¶€í•˜ì—¬ì•¼ í•œë‹¤. <ê°œì • 2013. 1. 1., 2016. 12. 20., 2018. 12. 31., 2019. 12. 31., 2020. 12.\\n29.>\\n1. ì œ119ì¡°ì œ1í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ì´ìì†Œë“: ë‹¤ìŒ ê° ëª©ì˜ êµ¬ë¶„ì— ë”°ë¥¸ ê¸ˆì•¡\\nê°€. êµ­ê°€Â·ì§€ë°©ìì¹˜ë‹¨ì²´ ë° ë‚´êµ­ë²•ì¸ì´ ë°œí–‰í•˜ëŠ” ì±„ê¶Œì—ì„œ ë°œìƒí•˜ëŠ” ì´ìì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 14\\në‚˜. ê°€ëª© ì™¸ì˜ ì´ìì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20\\n2. ì œ119ì¡°ì œ2í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ë°°ë‹¹ì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20\\n3. ì œ119ì¡°ì œ4í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ì„ ë°•ë“±ì„ëŒ€ì†Œë“ ë° ê°™ì€ ì¡° ì œ5í˜¸(ì¡°ì„¸ì¡°ì•½ì— ë”°ë¼ êµ­ë‚´ì›ì²œ ì‚¬ì—…ì†Œë“ìœ¼ë¡œ ê³¼ì„¸\\ní•  ìˆ˜ ìˆëŠ” ì†Œë“ì€ ì œì™¸í•œë‹¤)ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ì‚¬ì—…ì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 2\\n4. ì œ119ì¡°ì œ6í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ì¸ì ìš©ì—­ì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20. ë‹¤ë§Œ, êµ­ì™¸ì—ì„œ ì œê³µí•˜ëŠ” ì¸ì ìš©ì—­ ì¤‘ëŒ€\\ní†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ìš©ì—­ì„ ì œê³µí•¨ìœ¼ë¡œì¨ ë°œìƒí•˜ëŠ” ì†Œë“ì´ ì¡°ì„¸ì¡°ì•½ì— ë”°ë¼ êµ­ë‚´ì—ì„œ ë°œìƒí•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ëŠ” ì†Œë“\\nì— ëŒ€í•´ì„œëŠ” ê·¸ ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 3ìœ¼ë¡œ í•œë‹¤.\\n5. ì œ119ì¡°ì œ9í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ë¶€ë™ì‚°ë“±ì–‘ë„ì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 10. ë‹¤ë§Œ, ì–‘ë„í•œ ìì‚°ì˜ ì·¨ë“ê°€ì•¡ ë° ì–‘\\në„ë¹„ìš©ì´ í™•ì¸ë˜ëŠ” ê²½ìš°ì—ëŠ” ê·¸ ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 10ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ê³¼ ê·¸ ìì‚°ì˜ ì–‘ë„ì°¨ìµì˜ 100ë¶„ì˜ 20ì—\\ní•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ ì¤‘ ì ì€ ê¸ˆì•¡ìœ¼ë¡œ í•œë‹¤.\\n6. ì œ119ì¡°ì œ10í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ì‚¬ìš©ë£Œì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20\\n7. ì œ119ì¡°ì œ11í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ìœ ê°€ì¦ê¶Œì–‘ë„ì†Œë“: ì§€ê¸‰ê¸ˆì•¡(ì œ126ì¡°ì œ6í•­ì— í•´ë‹¹í•˜ëŠ” ê²½ìš°ì—ëŠ” ê°™ì€ í•­ì˜ ì •\\nìƒê°€ê²©ì„ ë§í•œë‹¤. ì´í•˜ ì´ í˜¸ì—ì„œ ê°™ë‹¤)ì˜ 100ë¶„ì˜ 10. ë‹¤ë§Œ, ì œ126ì¡°ì œ1í•­ì œ1í˜¸ì— ë”°ë¼ í•´ë‹¹ ìœ ê°€ì¦ê¶Œì˜ ì·¨ë“ê°€\\nì•¡ ë° ì–‘ë„ë¹„ìš©ì´ í™•ì¸ë˜ëŠ” ê²½ìš°ì—ëŠ” ê·¸ ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 10ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ê³¼ ê°™ì€ í˜¸ì— ë”°ë¼ ê³„ì‚°í•œ ê¸ˆì•¡\\nì˜ 100ë¶„ì˜ 20ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ ì¤‘ ì ì€ ê¸ˆì•¡ìœ¼ë¡œ í•œë‹¤.\\n8. ì œ119ì¡°ì œ12í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ê¸°íƒ€ì†Œë“: ë‹¤ìŒ ê° ëª©ì˜ êµ¬ë¶„ì— ë”°ë¥¸ ê¸ˆì•¡\\nê°€. ì œ119ì¡°ì œ12í˜¸ì¹´ëª©ì˜ ì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 15\\në‚˜. ì œ119ì¡°ì œ12í˜¸íƒ€ëª©ì˜ ì†Œë“: ë‹¤ìŒì˜ êµ¬ë¶„ì— ë”°ë¥¸ ê¸ˆì•¡. ë‹¤ë§Œ, ê°€ìƒìì‚°ì„ êµí™˜í•˜ê±°ë‚˜ ì¸ì¶œí•˜ëŠ” ê²½ìš°ì—ëŠ” ë‹¤ìŒ\\nì˜ êµ¬ë¶„ì— ìƒë‹¹í•˜ëŠ” ê¸ˆì•¡ìœ¼ë¡œì„œ ê°€ìƒìì‚° ë‹¨ìœ„ë¡œ í‘œì‹œí•œ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ê¸ˆì•¡ìœ¼ë¡œ í•œë‹¤.\\n1) ì œ126ì¡°ì œ1í•­ì œ3í˜¸ì— ë”°ë¼ ê°€ìƒìì‚°ì˜ í•„ìš”ê²½ë¹„ê°€ í™•ì¸ë˜ëŠ” ê²½ìš°: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 10ì— í•´ë‹¹í•˜ëŠ” ê¸ˆ\\nì•¡ê³¼ ê°™ì€ í˜¸ì— ë”°ë¼ ê³„ì‚°í•œ ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ ì¤‘ ì ì€ ê¸ˆì•¡'),\n",
       " Document(id='15f6746f-4e63-4775-a47e-c72298375620', metadata={'source': './tax_combined_final.txt'}, page_content='ì†Œë“ì„¸ë²•')]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore_from_docs.as_retriever(search_kwargs={'k':3})\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0682076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import List, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.documents import Document\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict) :\n",
    "    query:str\n",
    "    context: Annotated[List[Document], operator.add]\n",
    "    answer:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d0495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from typing import Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1986a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-1.0.7-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langgraph) (1.2.7)\n",
      "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.7 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langgraph) (2.12.5)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core>=0.1->langgraph) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core>=0.1->langgraph) (0.14.0)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.12.2-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soobi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.6.3)\n",
      "Downloading langgraph-1.0.7-py3-none-any.whl (157 kB)\n",
      "Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.3.3-py3-none-any.whl (67 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Downloading ormsgpack-1.12.2-cp312-cp312-win_amd64.whl (117 kB)\n",
      "Installing collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "Successfully installed langgraph-1.0.7 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.7 langgraph-sdk-0.3.3 ormsgpack-1.12.2 xxhash-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soobi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8cc9c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph_builer = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b9e24632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node:retrieve, generate ë…¸íŠ¸\n",
    "\n",
    "def retrieveDoc(state:AgentState):\n",
    "    query=state['query']\n",
    "    docs =retriever.invoke(query)\n",
    "    return {'context':docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "48fdd4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LangSmith API in Settings > API Keys\n",
    "# Make sure API key env var is set:\n",
    "# import os; os.environ[\"LANGSMITH_API_KEY\"] = \"<your-api-key>\"\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "prompt = client.pull_prompt(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6368567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAnswer(state:AgentState):\n",
    "    context= state['context']\n",
    "    query= state['query']\n",
    "    lag_chain = prompt | llm\n",
    "    response = lag_chain.invoke({'question':query, 'context': context})\n",
    "\n",
    "    return {'answer': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9031da6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x261e96aa870>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builer.add_node('retrieve', retrieve)\n",
    "graph_builer.add_node('generate', generate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8464ade1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x261e96aa870>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builer.add_edge(START,'retrieve')\n",
    "graph_builer.add_edge('retrieve', 'generate')\n",
    "graph_builer.add_edge('generate', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a10c1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph= graph_builer.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e3ca1074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "437a11c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'ì—°ë´‰ 5ì²œë§Œì› ì§ì¥ì¸ì˜ ì†Œë“ì„¸ëŠ”?',\n",
       " 'context': [Document(id='5a211886-c6db-4fd5-9e77-a4375dd2ee6d', metadata={'source': './tax_combined_final.txt'}, page_content='5. ê³µì ì—°ê¸ˆì†Œë“ì— ëŒ€í•´ì„œëŠ” ê¸°ë³¸ì„¸ìœ¨\\n5ì˜2.ì œ20ì¡°ì˜3ì œ1í•­ì œ2í˜¸ë‚˜ëª© ë° ë‹¤ëª©ì— ë”°ë¥¸ ì—°ê¸ˆê³„ì¢Œ ë‚©ì…ì•¡ì´ë‚˜ ìš´ìš©ì‹¤ì ì— ë”°ë¼ ì¦ê°€ëœ ê¸ˆì•¡ì„ ì—°ê¸ˆìˆ˜ë ¹í•œ\\nì—°ê¸ˆì†Œë“ì— ëŒ€í•´ì„œëŠ” ë‹¤ìŒ ê° ëª©ì˜ êµ¬ë¶„ì— ë”°ë¥¸ ì„¸ìœ¨. ì´ ê²½ìš° ê° ëª©ì˜ ìš”ê±´ì„ ë™ì‹œì— ì¶©ì¡±í•˜ëŠ” ë•Œì—ëŠ” ë‚®ì€ ì„¸ìœ¨\\nì„ ì ìš©í•œë‹¤.\\nê°€. ì—°ê¸ˆì†Œë“ìì˜ ë‚˜ì´ì— ë”°ë¥¸ ë‹¤ìŒì˜ ì„¸ìœ¨\\n|ë‚˜ì´(ì—°ê¸ˆìˆ˜ë ¹ì¼ í˜„ì¬)| ì„¸ìœ¨   |\\n| ----------- | ----------- |\\n| 70ì„¸ ë¯¸ë§Œ | 100ë¶„ì˜ 5 |\\n| 70ì„¸ ì´ìƒ 80ì„¸ ë¯¸ë§Œ | 100ë¶„ì˜ 4 |\\n| 80ì„¸ ì´ìƒ | 100ë¶„ì˜ 3 |\\në‚˜. ì‚­ì œ <2014. 12. 23.>'),\n",
       "  Document(id='a6c9015f-092f-4aa3-819b-e23588bb0a0f', metadata={'source': './tax_combined_final.txt'}, page_content='ì†Œë“ì„¸ë²•\\ní•˜ëŠ” ì(ì œ119ì¡°ì œ9í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ë¶€ë™ì‚°ë“±ì–‘ë„ì†Œë“ì„ ì§€ê¸‰í•˜ëŠ” ê±°ì£¼ì ë° ë¹„ê±°ì£¼ìëŠ” ì œì™¸í•œë‹¤)ëŠ” ì œ127ì¡°\\nì—ë„ ë¶ˆêµ¬í•˜ê³  ê·¸ ì†Œë“ì„ ì§€ê¸‰í•  ë•Œì— ë‹¤ìŒ ê° í˜¸ì˜ ê¸ˆì•¡ì„ ê·¸ ë¹„ê±°ì£¼ìì˜ êµ­ë‚´ì›ì²œì†Œë“ì— ëŒ€í•œ ì†Œë“ì„¸ë¡œì„œ ì›ì²œì§•\\nìˆ˜í•˜ì—¬ ê·¸ ì›ì²œì§•ìˆ˜í•œ ë‚ ì´ ì†í•˜ëŠ” ë‹¬ì˜ ë‹¤ìŒ ë‹¬ 10ì¼ê¹Œì§€ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ë°”ì— ë”°ë¼ ì›ì²œì§•ìˆ˜ ê´€í•  ì„¸ë¬´ì„œ,\\ní•œêµ­ì€í–‰ ë˜ëŠ” ì²´ì‹ ê´€ì„œì— ë‚©ë¶€í•˜ì—¬ì•¼ í•œë‹¤. <ê°œì • 2013. 1. 1., 2016. 12. 20., 2018. 12. 31., 2019. 12. 31., 2020. 12.\\n29.>\\n1. ì œ119ì¡°ì œ1í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ì´ìì†Œë“: ë‹¤ìŒ ê° ëª©ì˜ êµ¬ë¶„ì— ë”°ë¥¸ ê¸ˆì•¡\\nê°€. êµ­ê°€Â·ì§€ë°©ìì¹˜ë‹¨ì²´ ë° ë‚´êµ­ë²•ì¸ì´ ë°œí–‰í•˜ëŠ” ì±„ê¶Œì—ì„œ ë°œìƒí•˜ëŠ” ì´ìì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 14\\në‚˜. ê°€ëª© ì™¸ì˜ ì´ìì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20\\n2. ì œ119ì¡°ì œ2í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ë°°ë‹¹ì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20\\n3. ì œ119ì¡°ì œ4í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ì„ ë°•ë“±ì„ëŒ€ì†Œë“ ë° ê°™ì€ ì¡° ì œ5í˜¸(ì¡°ì„¸ì¡°ì•½ì— ë”°ë¼ êµ­ë‚´ì›ì²œ ì‚¬ì—…ì†Œë“ìœ¼ë¡œ ê³¼ì„¸\\ní•  ìˆ˜ ìˆëŠ” ì†Œë“ì€ ì œì™¸í•œë‹¤)ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ì‚¬ì—…ì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 2\\n4. ì œ119ì¡°ì œ6í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ì¸ì ìš©ì—­ì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20. ë‹¤ë§Œ, êµ­ì™¸ì—ì„œ ì œê³µí•˜ëŠ” ì¸ì ìš©ì—­ ì¤‘ëŒ€\\ní†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ìš©ì—­ì„ ì œê³µí•¨ìœ¼ë¡œì¨ ë°œìƒí•˜ëŠ” ì†Œë“ì´ ì¡°ì„¸ì¡°ì•½ì— ë”°ë¼ êµ­ë‚´ì—ì„œ ë°œìƒí•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ëŠ” ì†Œë“\\nì— ëŒ€í•´ì„œëŠ” ê·¸ ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 3ìœ¼ë¡œ í•œë‹¤.\\n5. ì œ119ì¡°ì œ9í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ë¶€ë™ì‚°ë“±ì–‘ë„ì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 10. ë‹¤ë§Œ, ì–‘ë„í•œ ìì‚°ì˜ ì·¨ë“ê°€ì•¡ ë° ì–‘\\në„ë¹„ìš©ì´ í™•ì¸ë˜ëŠ” ê²½ìš°ì—ëŠ” ê·¸ ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 10ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ê³¼ ê·¸ ìì‚°ì˜ ì–‘ë„ì°¨ìµì˜ 100ë¶„ì˜ 20ì—\\ní•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ ì¤‘ ì ì€ ê¸ˆì•¡ìœ¼ë¡œ í•œë‹¤.\\n6. ì œ119ì¡°ì œ10í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ì‚¬ìš©ë£Œì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20\\n7. ì œ119ì¡°ì œ11í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ìœ ê°€ì¦ê¶Œì–‘ë„ì†Œë“: ì§€ê¸‰ê¸ˆì•¡(ì œ126ì¡°ì œ6í•­ì— í•´ë‹¹í•˜ëŠ” ê²½ìš°ì—ëŠ” ê°™ì€ í•­ì˜ ì •\\nìƒê°€ê²©ì„ ë§í•œë‹¤. ì´í•˜ ì´ í˜¸ì—ì„œ ê°™ë‹¤)ì˜ 100ë¶„ì˜ 10. ë‹¤ë§Œ, ì œ126ì¡°ì œ1í•­ì œ1í˜¸ì— ë”°ë¼ í•´ë‹¹ ìœ ê°€ì¦ê¶Œì˜ ì·¨ë“ê°€\\nì•¡ ë° ì–‘ë„ë¹„ìš©ì´ í™•ì¸ë˜ëŠ” ê²½ìš°ì—ëŠ” ê·¸ ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 10ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ê³¼ ê°™ì€ í˜¸ì— ë”°ë¼ ê³„ì‚°í•œ ê¸ˆì•¡\\nì˜ 100ë¶„ì˜ 20ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ ì¤‘ ì ì€ ê¸ˆì•¡ìœ¼ë¡œ í•œë‹¤.\\n8. ì œ119ì¡°ì œ12í˜¸ì— ë”°ë¥¸ êµ­ë‚´ì›ì²œ ê¸°íƒ€ì†Œë“: ë‹¤ìŒ ê° ëª©ì˜ êµ¬ë¶„ì— ë”°ë¥¸ ê¸ˆì•¡\\nê°€. ì œ119ì¡°ì œ12í˜¸ì¹´ëª©ì˜ ì†Œë“: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 15\\në‚˜. ì œ119ì¡°ì œ12í˜¸íƒ€ëª©ì˜ ì†Œë“: ë‹¤ìŒì˜ êµ¬ë¶„ì— ë”°ë¥¸ ê¸ˆì•¡. ë‹¤ë§Œ, ê°€ìƒìì‚°ì„ êµí™˜í•˜ê±°ë‚˜ ì¸ì¶œí•˜ëŠ” ê²½ìš°ì—ëŠ” ë‹¤ìŒ\\nì˜ êµ¬ë¶„ì— ìƒë‹¹í•˜ëŠ” ê¸ˆì•¡ìœ¼ë¡œì„œ ê°€ìƒìì‚° ë‹¨ìœ„ë¡œ í‘œì‹œí•œ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ê¸ˆì•¡ìœ¼ë¡œ í•œë‹¤.\\n1) ì œ126ì¡°ì œ1í•­ì œ3í˜¸ì— ë”°ë¼ ê°€ìƒìì‚°ì˜ í•„ìš”ê²½ë¹„ê°€ í™•ì¸ë˜ëŠ” ê²½ìš°: ì§€ê¸‰ê¸ˆì•¡ì˜ 100ë¶„ì˜ 10ì— í•´ë‹¹í•˜ëŠ” ê¸ˆ\\nì•¡ê³¼ ê°™ì€ í˜¸ì— ë”°ë¼ ê³„ì‚°í•œ ê¸ˆì•¡ì˜ 100ë¶„ì˜ 20ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ ì¤‘ ì ì€ ê¸ˆì•¡'),\n",
       "  Document(id='15f6746f-4e63-4775-a47e-c72298375620', metadata={'source': './tax_combined_final.txt'}, page_content='ì†Œë“ì„¸ë²•')],\n",
       " 'answer': AIMessage(content='ì—°ë´‰ 5ì²œë§Œì›ì„ ë°›ëŠ” ì§ì¥ì¸ì˜ ì†Œë“ì„¸ëŠ” ê°œì¸ì˜ ê³µì œ ê¸ˆì•¡ê³¼ ì„¸ìœ¨ì— ë”°ë¼ ë‹¬ë¼ì§€ì§€ë§Œ, ëŒ€ëµ 500ë§Œì›ì—ì„œ 600ë§Œì› ì •ë„ë¡œ ì˜ˆìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì •í™•í•œ ì„¸ê¸ˆ ê³„ì‚°ì€ ê°œì¸ì˜ ìƒí™©ì— ë”°ë¼ ë‹¤ë¥´ë¯€ë¡œ, ì„¸ë¬´ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ìì„¸í•œ ì„¸ì•¡ ê³„ì‚°ì„ ì›í•˜ì‹œë©´ êµ­ì„¸ì²­ì˜ ê´€ë ¨ ìë£Œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 1358, 'total_tokens': 1451, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-D1uKxpg7550H3PsRXWhCt2Uhm4TgX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf550-9962-7ff1-b4d7-dd179ee01f0e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1358, 'output_tokens': 93, 'total_tokens': 1451, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {'query': query}\n",
    "graph.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
